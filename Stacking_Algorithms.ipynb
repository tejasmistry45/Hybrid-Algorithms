{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load and prepare the data\n",
        "data = pd.read_csv('songsDataset.csv',nrows=1000)\n",
        "data.columns = data.columns.str.strip().str.replace(\"'\", \"\")\n",
        "\n",
        "# Create a sparse matrix from the data\n",
        "sparse_item_matrix = csr_matrix((data[\"rating\"].values, (data[\"userID\"].values, data[\"songID\"].values)))\n",
        "\n",
        "# Compute the cosine similarity between items\n",
        "item_similarity = cosine_similarity(sparse_item_matrix.T)\n",
        "\n",
        "# Create user-item matrix\n",
        "user_item_matrix = data.pivot_table(index='userID', columns='songID', values='rating').fillna(0)\n",
        "\n",
        "# Compute the cosine similarity between users\n",
        "user_similarity_matrix = cosine_similarity(user_item_matrix)\n",
        "user_similarity_df = pd.DataFrame(user_similarity_matrix, index=user_item_matrix.index, columns=user_item_matrix.index)\n"
      ],
      "metadata": {
        "id": "7XJDOHK4VphC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to get similar items\n",
        "def get_similar_items(song_id, item_similarity, top_n=5):\n",
        "    similar_scores = item_similarity[song_id].flatten()\n",
        "    top_n_indices = similar_scores.argsort()[:-top_n-1:-1][1:]\n",
        "    return top_n_indices\n",
        "\n",
        "# Create a function to recommend songs (item-based)\n",
        "def recommend_songs_item_based(user_id, sparse_item_matrix, item_similarity, top_n=5):\n",
        "    user_ratings = sparse_item_matrix[user_id].toarray().flatten()\n",
        "    user_ratings = {i: rating for i, rating in enumerate(user_ratings) if rating > 0}\n",
        "    recommendations = {}\n",
        "    for song_id, rating in user_ratings.items():\n",
        "        similar_items = get_similar_items(song_id, item_similarity, top_n)\n",
        "        for similar_item in similar_items:\n",
        "            if similar_item in recommendations:\n",
        "                recommendations[similar_item] += rating\n",
        "            else:\n",
        "                recommendations[similar_item] = rating\n",
        "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [song_id for song_id, _ in recommendations[:top_n]]\n",
        "\n",
        "# Create a function to get similar users\n",
        "def get_user_similarity(target_user, user_similarity_df, top_n=5):\n",
        "    similar_scores = user_similarity_df[target_user].sort_values(ascending=False)\n",
        "    similar_users = similar_scores.iloc[1:top_n+1].index.tolist()\n",
        "    return similar_users\n",
        "\n",
        "# Create a function to recommend songs (user-based)\n",
        "def recommend_songs_user_based(userID, user_item_matrix, user_similarity_df, num_recs=5):\n",
        "    similar_users = get_user_similarity(userID, user_similarity_df)\n",
        "    recommended_songs = []\n",
        "    for similar_userID in similar_users:\n",
        "        for songID, rating in user_item_matrix.loc[similar_userID].items():\n",
        "            if rating > 0:\n",
        "                recommended_songs.append((songID, rating))\n",
        "    recommended_songs = sorted(recommended_songs, key=lambda x: x[1], reverse=True)\n",
        "    return [songID for songID, _ in recommended_songs[:num_recs]]\n"
      ],
      "metadata": {
        "id": "JHWIi-vpVpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for a user using both methods\n",
        "def generate_predictions(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df, top_n=5):\n",
        "    item_based_recs = recommend_songs_item_based(user_id, sparse_item_matrix, item_similarity, top_n)\n",
        "    user_based_recs = recommend_songs_user_based(user_id, user_item_matrix, user_similarity_df, top_n)\n",
        "    return item_based_recs, user_based_recs\n",
        "\n",
        "# Example for a specific user\n",
        "user_id = int(input(\"Enter UserID: \"))\n",
        "item_based_recs, user_based_recs = generate_predictions(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df)\n",
        "print(\"Item-based recommendations:\", item_based_recs)\n",
        "print(\"User-based recommendations:\", user_based_recs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa7ph5s2VpmY",
        "outputId": "3b1fca75-39b7-4e2a-a1bb-33bc015233e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter UserID: 5\n",
            "Item-based recommendations: [128621, 98571, 8063, 95898, 24033]\n",
            "User-based recommendations: [105433, 106513, 5542, 12447, 19690]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define a fixed length for the recommendation lists\n",
        "FIXED_LENGTH = 5\n",
        "\n",
        "# Function to pad lists to a fixed length\n",
        "def pad_list(lst, length):\n",
        "    return lst + [0] * (length - len(lst))\n",
        "\n",
        "# Prepare features and target for base models\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Assuming we have actual ratings for the songs\n",
        "for user_id in data['userID'].unique()[:100]:\n",
        "    user_data = data[data['userID'] == user_id]\n",
        "    for song_id in user_data['songID']:\n",
        "        item_based_recs, user_based_recs = generate_predictions(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df)\n",
        "        item_based_recs = pad_list(item_based_recs, FIXED_LENGTH)\n",
        "        user_based_recs = pad_list(user_based_recs, FIXED_LENGTH)\n",
        "        X.append(item_based_recs + user_based_recs)  # Combine both sets of recommendations\n",
        "        y.append(user_data[user_data['songID'] == song_id]['rating'].values[0])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train base models\n",
        "dt = DecisionTreeRegressor()\n",
        "knn = KNeighborsRegressor()\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Generate base model predictions\n",
        "pred_dt = dt.predict(X_train)\n",
        "pred_knn = knn.predict(X_train)\n",
        "pred_lr = lr.predict(X_train)\n"
      ],
      "metadata": {
        "id": "rAWlZLmcVppM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Stack base model predictions as features for the meta-model\n",
        "stacked_features = np.column_stack((pred_dt, pred_knn, pred_lr))\n",
        "\n",
        "# Train the meta-model\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(stacked_features, y_train)\n",
        "\n",
        "# Evaluate the meta-model\n",
        "pred_dt_test = dt.predict(X_test)\n",
        "pred_knn_test = knn.predict(X_test)\n",
        "pred_lr_test = lr.predict(X_test)\n",
        "\n",
        "stacked_features_test = np.column_stack((pred_dt_test, pred_knn_test, pred_lr_test))\n",
        "y_pred = meta_model.predict(stacked_features_test)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMIB6gZZVxUe",
        "outputId": "a5bb629b-f97b-42b5-fdaa-d2f087d0381c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.6418628354119422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check model accuracy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo4Jm0rlWbTc",
        "outputId": "5b36c905-8169-42ec-f6cd-b70ccbe5342e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.6418628354119422\n",
            "Mean Absolute Error (MAE): 1.0262380952380952\n",
            "Root Mean Squared Error (RMSE): 1.2813519561041542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_final_recommendation(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df, dt, knn, lr, meta_model, top_n=5):\n",
        "    item_based_recs, user_based_recs = generate_predictions(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df)\n",
        "    item_based_recs = pad_list(item_based_recs, FIXED_LENGTH)\n",
        "    user_based_recs = pad_list(user_based_recs, FIXED_LENGTH)\n",
        "    combined_features = np.array(item_based_recs + user_based_recs).reshape(1, -1)\n",
        "    pred_dt = dt.predict(combined_features)\n",
        "    pred_knn = knn.predict(combined_features)\n",
        "    pred_lr = lr.predict(combined_features)\n",
        "    stacked_features = np.column_stack((pred_dt, pred_knn, pred_lr))\n",
        "    final_scores = meta_model.predict(stacked_features)\n",
        "\n",
        "    # Combine the scores with the item-based and user-based recommendations\n",
        "    combined_recs = {rec: score for rec, score in zip(item_based_recs + user_based_recs, final_scores.flatten())}\n",
        "    sorted_recs = sorted(combined_recs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top_n unique recommendations\n",
        "    top_recs = []\n",
        "    seen = set()\n",
        "    for rec, score in sorted_recs:\n",
        "        if rec not in seen:\n",
        "            top_recs.append(rec)\n",
        "            seen.add(rec)\n",
        "        if len(top_recs) == top_n:\n",
        "            break\n",
        "\n",
        "    return top_recs"
      ],
      "metadata": {
        "id": "RqRzid6sWHTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = int(input(\"Enter UserID: \"))\n",
        "final_recs = make_final_recommendation(user_id, sparse_item_matrix, item_similarity, user_item_matrix, user_similarity_df, dt, knn, lr, meta_model)\n",
        "print(\"Final recommendations for user\", user_id, \":\", final_recs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb5iD9OOWJMb",
        "outputId": "84c9d4d2-201e-40d1-d558-72c0952495b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter UserID: 9\n",
            "Final recommendations for user 9 : [130766]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA2SiRndYWoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}